{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data for first 3 variables of final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/22 14:35:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/22 14:36:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/09/22 14:36:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# setup spark\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"aggregate data for first 3 final model variables\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"15g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet(\"../data/curated/fraud/transactions_withoutfraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12143162"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some new columns\n",
    "data = data.withColumn(\"Week\", F.weekofyear(\"order_datetime\"))\\\n",
    "        .withColumn(\"Year\", F.year(\"order_datetime\"))\\\n",
    "        .withColumn(\"Month\", F.month(\"order_datetime\"))\\\n",
    "        .withColumn(\"Day\", F.dayofmonth(\"order_datetime\"))\\\n",
    "        .withColumn(\"Fortnight\", ((F.col(\"Week\")+1)/2).cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>user_id2</th><th>order_datetime2</th><th>fraud rate</th><th>fraud2</th><th>user_id</th><th>merchant_abn</th><th>dollar_value</th><th>order_id</th><th>order_datetime</th><th>user_id3</th><th>order_datetime3</th><th>fraud_probability</th><th>fraud3</th><th>Week</th><th>Year</th><th>Month</th><th>Day</th><th>Fortnight</th></tr>\n",
       "<tr><td>1</td><td>2021-04-18</td><td>9.290493571169254</td><td>0</td><td>1</td><td>82912636758</td><td>1435.794850018464</td><td>e79aeb7e-043b-45f...</td><td>2021-04-18</td><td>null</td><td>null</td><td>null</td><td>null</td><td>15</td><td>2021</td><td>4</td><td>18</td><td>8</td></tr>\n",
       "<tr><td>1</td><td>2021-04-23</td><td>9.287148398864032</td><td>0</td><td>1</td><td>33604812025</td><td>93.01406474076359</td><td>ea1107f4-3d57-441...</td><td>2021-04-23</td><td>null</td><td>null</td><td>null</td><td>null</td><td>16</td><td>2021</td><td>4</td><td>23</td><td>8</td></tr>\n",
       "<tr><td>1</td><td>2021-05-02</td><td>9.287148398864032</td><td>0</td><td>1</td><td>64203420245</td><td>13.795710586158274</td><td>7b2952e9-17d8-429...</td><td>2021-05-02</td><td>null</td><td>null</td><td>null</td><td>null</td><td>17</td><td>2021</td><td>5</td><td>2</td><td>9</td></tr>\n",
       "<tr><td>1</td><td>2021-06-08</td><td>9.287148398864032</td><td>0</td><td>1</td><td>19575005485</td><td>14.277862286033697</td><td>a72b651c-bffb-4a9...</td><td>2021-06-08</td><td>null</td><td>null</td><td>null</td><td>null</td><td>23</td><td>2021</td><td>6</td><td>8</td><td>12</td></tr>\n",
       "<tr><td>1</td><td>2021-07-23</td><td>9.287148398864032</td><td>0</td><td>1</td><td>46298404088</td><td>92.31309395478299</td><td>2773225f-80a5-411...</td><td>2021-07-23</td><td>null</td><td>null</td><td>null</td><td>null</td><td>29</td><td>2021</td><td>7</td><td>23</td><td>15</td></tr>\n",
       "<tr><td>1</td><td>2021-09-30</td><td>9.290493571169254</td><td>0</td><td>1</td><td>46674437504</td><td>517.5794837525516</td><td>e5746eb5-19e0-43d...</td><td>2021-09-30</td><td>null</td><td>null</td><td>null</td><td>null</td><td>39</td><td>2021</td><td>9</td><td>30</td><td>20</td></tr>\n",
       "<tr><td>1</td><td>2021-10-30</td><td>9.287148398864032</td><td>0</td><td>1</td><td>51279178333</td><td>9.611126453764486</td><td>bfaf2ae8-068f-48f...</td><td>2021-10-30</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43</td><td>2021</td><td>10</td><td>30</td><td>22</td></tr>\n",
       "<tr><td>1</td><td>2021-11-03</td><td>9.287148398864032</td><td>0</td><td>1</td><td>98268965514</td><td>269.4124531844491</td><td>7d0a4cce-0d66-455...</td><td>2021-11-03</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44</td><td>2021</td><td>11</td><td>3</td><td>22</td></tr>\n",
       "<tr><td>1</td><td>2021-11-04</td><td>9.466559691318782</td><td>0</td><td>1</td><td>49891706470</td><td>46.15699347673238</td><td>df726124-0859-45c...</td><td>2021-11-04</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44</td><td>2021</td><td>11</td><td>4</td><td>22</td></tr>\n",
       "<tr><td>1</td><td>2021-11-04</td><td>9.466559691318782</td><td>0</td><td>1</td><td>45572698303</td><td>333.761456660311</td><td>7d351762-2877-4c2...</td><td>2021-11-04</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44</td><td>2021</td><td>11</td><td>4</td><td>22</td></tr>\n",
       "<tr><td>1</td><td>2021-11-24</td><td>9.460709429814758</td><td>0</td><td>1</td><td>86388904574</td><td>153.97261411042084</td><td>30c2f380-2dee-487...</td><td>2021-11-24</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47</td><td>2021</td><td>11</td><td>24</td><td>24</td></tr>\n",
       "<tr><td>1</td><td>2021-11-24</td><td>9.460709429814758</td><td>0</td><td>1</td><td>66464469789</td><td>125.12302531303199</td><td>36ca67f3-89d8-410...</td><td>2021-11-24</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47</td><td>2021</td><td>11</td><td>24</td><td>24</td></tr>\n",
       "<tr><td>1</td><td>2021-11-24</td><td>9.460709429814758</td><td>0</td><td>1</td><td>38736067045</td><td>288.32635847102193</td><td>8b7734ac-78e9-48d...</td><td>2021-11-24</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47</td><td>2021</td><td>11</td><td>24</td><td>24</td></tr>\n",
       "<tr><td>1</td><td>2021-11-26</td><td>9.3557502552778</td><td>0</td><td>1</td><td>46451548968</td><td>72.61581642788431</td><td>76bab304-fa2d-400...</td><td>2021-11-26</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47</td><td>2021</td><td>11</td><td>26</td><td>24</td></tr>\n",
       "<tr><td>1</td><td>2021-11-26</td><td>9.3557502552778</td><td>0</td><td>1</td><td>49167531725</td><td>51.58228625503599</td><td>7080c274-17f7-4cc...</td><td>2021-11-26</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47</td><td>2021</td><td>11</td><td>26</td><td>24</td></tr>\n",
       "<tr><td>1</td><td>2021-12-27</td><td>9.473052336568745</td><td>0</td><td>1</td><td>89430765327</td><td>526.5123512840586</td><td>f4d38480-5fbc-42c...</td><td>2021-12-27</td><td>null</td><td>null</td><td>null</td><td>null</td><td>52</td><td>2021</td><td>12</td><td>27</td><td>26</td></tr>\n",
       "<tr><td>1</td><td>2021-12-27</td><td>9.473052336568745</td><td>0</td><td>1</td><td>64203420245</td><td>13.959124115149173</td><td>65f10d1d-6a42-4ed...</td><td>2021-12-27</td><td>null</td><td>null</td><td>null</td><td>null</td><td>52</td><td>2021</td><td>12</td><td>27</td><td>26</td></tr>\n",
       "<tr><td>1</td><td>2022-01-04</td><td>9.460709429814758</td><td>0</td><td>1</td><td>29616684420</td><td>191.34317468230807</td><td>b1bf457f-d873-423...</td><td>2022-01-04</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1</td><td>2022</td><td>1</td><td>4</td><td>1</td></tr>\n",
       "<tr><td>1</td><td>2022-01-04</td><td>9.460709429814758</td><td>0</td><td>1</td><td>46564887665</td><td>380.0259581041301</td><td>bcae03d6-f1bb-4fd...</td><td>2022-01-04</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1</td><td>2022</td><td>1</td><td>4</td><td>1</td></tr>\n",
       "<tr><td>1</td><td>2022-02-24</td><td>9.290493571169254</td><td>0</td><td>1</td><td>90568944804</td><td>811.416129781905</td><td>a43c190e-2cce-431...</td><td>2022-02-24</td><td>null</td><td>null</td><td>null</td><td>null</td><td>8</td><td>2022</td><td>2</td><td>24</td><td>4</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+---------------+-----------------+------+-------+------------+------------------+--------------------+--------------+--------+---------------+-----------------+------+----+----+-----+---+---------+\n",
       "|user_id2|order_datetime2|       fraud rate|fraud2|user_id|merchant_abn|      dollar_value|            order_id|order_datetime|user_id3|order_datetime3|fraud_probability|fraud3|Week|Year|Month|Day|Fortnight|\n",
       "+--------+---------------+-----------------+------+-------+------------+------------------+--------------------+--------------+--------+---------------+-----------------+------+----+----+-----+---+---------+\n",
       "|       1|     2021-04-18|9.290493571169254|     0|      1| 82912636758| 1435.794850018464|e79aeb7e-043b-45f...|    2021-04-18|    null|           null|             null|  null|  15|2021|    4| 18|        8|\n",
       "|       1|     2021-04-23|9.287148398864032|     0|      1| 33604812025| 93.01406474076359|ea1107f4-3d57-441...|    2021-04-23|    null|           null|             null|  null|  16|2021|    4| 23|        8|\n",
       "|       1|     2021-05-02|9.287148398864032|     0|      1| 64203420245|13.795710586158274|7b2952e9-17d8-429...|    2021-05-02|    null|           null|             null|  null|  17|2021|    5|  2|        9|\n",
       "|       1|     2021-06-08|9.287148398864032|     0|      1| 19575005485|14.277862286033697|a72b651c-bffb-4a9...|    2021-06-08|    null|           null|             null|  null|  23|2021|    6|  8|       12|\n",
       "|       1|     2021-07-23|9.287148398864032|     0|      1| 46298404088| 92.31309395478299|2773225f-80a5-411...|    2021-07-23|    null|           null|             null|  null|  29|2021|    7| 23|       15|\n",
       "|       1|     2021-09-30|9.290493571169254|     0|      1| 46674437504| 517.5794837525516|e5746eb5-19e0-43d...|    2021-09-30|    null|           null|             null|  null|  39|2021|    9| 30|       20|\n",
       "|       1|     2021-10-30|9.287148398864032|     0|      1| 51279178333| 9.611126453764486|bfaf2ae8-068f-48f...|    2021-10-30|    null|           null|             null|  null|  43|2021|   10| 30|       22|\n",
       "|       1|     2021-11-03|9.287148398864032|     0|      1| 98268965514| 269.4124531844491|7d0a4cce-0d66-455...|    2021-11-03|    null|           null|             null|  null|  44|2021|   11|  3|       22|\n",
       "|       1|     2021-11-04|9.466559691318782|     0|      1| 49891706470| 46.15699347673238|df726124-0859-45c...|    2021-11-04|    null|           null|             null|  null|  44|2021|   11|  4|       22|\n",
       "|       1|     2021-11-04|9.466559691318782|     0|      1| 45572698303|  333.761456660311|7d351762-2877-4c2...|    2021-11-04|    null|           null|             null|  null|  44|2021|   11|  4|       22|\n",
       "|       1|     2021-11-24|9.460709429814758|     0|      1| 86388904574|153.97261411042084|30c2f380-2dee-487...|    2021-11-24|    null|           null|             null|  null|  47|2021|   11| 24|       24|\n",
       "|       1|     2021-11-24|9.460709429814758|     0|      1| 66464469789|125.12302531303199|36ca67f3-89d8-410...|    2021-11-24|    null|           null|             null|  null|  47|2021|   11| 24|       24|\n",
       "|       1|     2021-11-24|9.460709429814758|     0|      1| 38736067045|288.32635847102193|8b7734ac-78e9-48d...|    2021-11-24|    null|           null|             null|  null|  47|2021|   11| 24|       24|\n",
       "|       1|     2021-11-26|  9.3557502552778|     0|      1| 46451548968| 72.61581642788431|76bab304-fa2d-400...|    2021-11-26|    null|           null|             null|  null|  47|2021|   11| 26|       24|\n",
       "|       1|     2021-11-26|  9.3557502552778|     0|      1| 49167531725| 51.58228625503599|7080c274-17f7-4cc...|    2021-11-26|    null|           null|             null|  null|  47|2021|   11| 26|       24|\n",
       "|       1|     2021-12-27|9.473052336568745|     0|      1| 89430765327| 526.5123512840586|f4d38480-5fbc-42c...|    2021-12-27|    null|           null|             null|  null|  52|2021|   12| 27|       26|\n",
       "|       1|     2021-12-27|9.473052336568745|     0|      1| 64203420245|13.959124115149173|65f10d1d-6a42-4ed...|    2021-12-27|    null|           null|             null|  null|  52|2021|   12| 27|       26|\n",
       "|       1|     2022-01-04|9.460709429814758|     0|      1| 29616684420|191.34317468230807|b1bf457f-d873-423...|    2022-01-04|    null|           null|             null|  null|   1|2022|    1|  4|        1|\n",
       "|       1|     2022-01-04|9.460709429814758|     0|      1| 46564887665| 380.0259581041301|bcae03d6-f1bb-4fd...|    2022-01-04|    null|           null|             null|  null|   1|2022|    1|  4|        1|\n",
       "|       1|     2022-02-24|9.290493571169254|     0|      1| 90568944804|  811.416129781905|a43c190e-2cce-431...|    2022-02-24|    null|           null|             null|  null|   8|2022|    2| 24|        4|\n",
       "+--------+---------------+-----------------+------+-------+------------+------------------+--------------------+--------------+--------+---------------+-----------------+------+----+----+-----+---+---------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dates that don't make a full week at start and end\n",
    "data = data.filter(data[\"order_datetime\"] >= F.lit('2021-03-01')) \\\n",
    "       .filter(data[\"order_datetime\"] <= F.lit('2022-08-14'))\n",
    "data\n",
    "\n",
    "## ONE THOUGHT: START THE WEEK ON A SUNDAY... but how does it affect the cycle? domain knowledge\n",
    "\n",
    "## THEORY: create a new column that is 1 day later than current date, and then take weekofyear based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12143162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate by Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by week and fortnight; retain sum of transactions, number of customers, number of transactions\n",
    "# transact_agg_by_comp_week = data.groupBy(\"Year\", \"Week\", \"merchant_abn\")\\\n",
    "#         .agg(F.sum(\"dollar_value\")\\\n",
    "#         .alias(\"sum_transactions\"), \\\n",
    "#          F.count(\"order_id\").alias(\"number_of_customers\"), \\\n",
    "#          F.countDistinct(\"user_id\").alias(\"distinct_customers\"))\n",
    "\n",
    "\n",
    "transact_agg_by_comp_fortnight = data.groupBy(\"Year\", \"Fortnight\", \"merchant_abn\")\\\n",
    "        .agg(F.sum(\"dollar_value\")\\\n",
    "        .alias(\"sum_transactions\"), \\\n",
    "         F.count(\"order_id\").alias(\"number_of_customers\"), \\\n",
    "         F.countDistinct(\"user_id\").alias(\"distinct_customers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose 6-4 split - 23 fortnights to 15 fortnights\n",
    "\n",
    "# # take everything else that doesn't satisfy validation set conditions\n",
    "# transact_agg_by_comp_fortnight_train = transact_agg_by_comp_fortnight.filter((F.col('Year') == 2021) | ((F.col('Year') == 2022) & (F.col('Fortnight') == 1))) \n",
    "\n",
    "# # take last 15 fortnights (because 2022 only gets data up to week 16)\n",
    "# transact_agg_by_comp_fortnight_validate = transact_agg_by_comp_fortnight.filter(((F.col('Year') == 2022) & (F.col('Fortnight') > 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# turn both into pandas dataframe\n",
    "# transact_agg_comp_week_df = transact_agg_by_comp_week.toPandas()\n",
    "\n",
    "transact_agg_comp_fortnight_df = transact_agg_by_comp_fortnight.toPandas()\n",
    "\n",
    "transact_agg_by_comp_fortnight_train_df = transact_agg_comp_fortnight_df[(transact_agg_comp_fortnight_df['Year'] == 2021) | \\\n",
    "    ((transact_agg_comp_fortnight_df['Year'] == 2022) & ((transact_agg_comp_fortnight_df['Fortnight'] == 1) | \\\n",
    "         (transact_agg_comp_fortnight_df['Fortnight'] == 26)))]\n",
    "\n",
    "transact_agg_by_comp_fortnight_validate_df = transact_agg_comp_fortnight_df[(transact_agg_comp_fortnight_df['Year'] == 2022) & \\\n",
    "    ((transact_agg_comp_fortnight_df['Fortnight'] > 1) & (transact_agg_comp_fortnight_df['Fortnight'] <= 16))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(transact_agg_comp_week_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88181"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_by_comp_fortnight_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55876"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_by_comp_fortnight_validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144057"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_fortnight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fill_na_df(transact_agg_comp_period_df, period):\n",
    "    \"\"\" helper function to create dataframe of all combos and 0 value for fillup \"\"\"\n",
    "\n",
    "    ## Fill up na\n",
    "    # get set of merchants\n",
    "    distinct_merchants = set(transact_agg_comp_period_df.merchant_abn)\n",
    "\n",
    "    # get set of year and period\n",
    "    year_period_set = list()\n",
    "\n",
    "    for id, dta in transact_agg_comp_period_df.groupby(['Year', period]):\n",
    "        year_period_set.append(id)\n",
    "\n",
    "    year_period_set = year_period_set[:-1]\n",
    "\n",
    "    years = [x[0] for x in year_period_set]\n",
    "    periods = [x[1] for x in year_period_set]\n",
    "\n",
    "    # make dataframes and join up\n",
    "    fill_na_time = pd.DataFrame({\"Year\": years, period: periods})\n",
    "\n",
    "    fill_na_companies = pd.DataFrame({\"merchant_abn\": list(distinct_merchants)})\n",
    "\n",
    "    fill_na_df = fill_na_time.merge(fill_na_companies, how = 'cross')\n",
    "\n",
    "    for col in transact_agg_comp_period_df.columns[3:]:\n",
    "        fill_na_df[col] = 0\n",
    "\n",
    "    return fill_na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_stray_period(transact_agg_comp_period_df, period):\n",
    "        \"\"\" correct problem of first few days of 2022 classified as wk 52 or fortnight 26, \n",
    "        which under our aggregation becomes separate week of 2022 week 52 or fortnight 26 \"\"\"\n",
    "\n",
    "        # figure out what the stray period number is\n",
    "        if period == 'Week':\n",
    "                stray_period_id = 52\n",
    "        else:\n",
    "                stray_period_id = 26\n",
    "\n",
    "        # take out just the stray period data\n",
    "        stray_period = transact_agg_comp_period_df[(transact_agg_comp_period_df[period] == stray_period_id) & \n",
    "                (transact_agg_comp_period_df['Year'] == 2022)]\n",
    "\n",
    "        transact_agg_comp_period_df = transact_agg_comp_period_df.drop(stray_period.index)\n",
    "\n",
    "        # update the stray period data's year\n",
    "        stray_period['Year'] = stray_period['Year']-1\n",
    "        # put it back\n",
    "        transact_agg_comp_period_df = pd.concat([transact_agg_comp_period_df, stray_period])\n",
    "\n",
    "        return transact_agg_comp_period_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(transact_agg_comp_period_df, fill_na_df, period):\n",
    "    \"\"\" Helper function to fill na \"\"\"\n",
    "    \n",
    "    transact_agg_comp_period_filled_df = pd.concat([transact_agg_comp_period_df, fill_na_df])\n",
    "    transact_agg_comp_period_filled_df = transact_agg_comp_period_filled_df.groupby(['Year', period, 'merchant_abn'])\\\n",
    "        .agg({'sum_transactions': sum, 'number_of_customers': sum, 'distinct_customers': sum})\n",
    "    transact_agg_comp_period_filled_df = transact_agg_comp_period_filled_df.reset_index()\n",
    "\n",
    "    return transact_agg_comp_period_filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prestart_filled_weeks(transact_agg_comp_period_filled_df, period): \n",
    "    \"\"\" Helper function to clean out wrongly filled 0 weeks (which will distort mean and variance) \"\"\"\n",
    "\n",
    "    # remove weeks before first BNPL transaction\n",
    "    transact_agg_comp_period_filled_adjusted_df = pd.DataFrame()\n",
    "\n",
    "    for id, dta in transact_agg_comp_period_filled_df.groupby(['merchant_abn']):\n",
    "\n",
    "        # iterate down the rows, and drop rows until first row where there is non0 transaction value\n",
    "        dta = dta.sort_values(['Year', 'Fortnight'])\n",
    "        dta.index = range(len(dta))\n",
    "\n",
    "        for row in dta.iterrows(): \n",
    "            if row[1][5] == 0: # if row's transaction value = 0\n",
    "                dta = dta.drop(row[0])\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "\n",
    "        transact_agg_comp_period_filled_adjusted_df = pd.concat([transact_agg_comp_period_filled_adjusted_df, dta])\n",
    "\n",
    "    return transact_agg_comp_period_filled_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transactions_agg_by_period(transact_agg_comp_period_df, period):\n",
    "    \"\"\" ETL function that runs all helpers to clean the aggregated merchant transaction data \"\"\"\n",
    "\n",
    "    fill_na_df = get_fill_na_df(transact_agg_comp_period_df, period)\n",
    "\n",
    "    transact_agg_comp_period_df = correct_stray_period(transact_agg_comp_period_df, period)\n",
    "\n",
    "    transact_agg_comp_period_filled_df = fill_na(transact_agg_comp_period_df, fill_na_df, period)\n",
    "\n",
    "    transact_agg_comp_period_filled_adjusted_df = remove_prestart_filled_weeks(transact_agg_comp_period_filled_df, period)\n",
    "\n",
    "    return transact_agg_comp_period_filled_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_4449/2094410300.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stray_period['Year'] = stray_period['Year']-1\n"
     ]
    }
   ],
   "source": [
    "# transact_agg_comp_week_filled_adjusted_df = get_transactions_agg_by_period(transact_agg_comp_week_df, 'Week')\n",
    "\n",
    "transact_agg_comp_fortnight_filled_adjusted_df = get_transactions_agg_by_period(transact_agg_comp_fortnight_df, 'Fortnight')\n",
    "\n",
    "transact_agg_comp_fortnight_fill_adjusted_train_df = get_transactions_agg_by_period(transact_agg_by_comp_fortnight_train_df, 'Fortnight')\n",
    "\n",
    "transact_agg_comp_fortnight_fill_adjusted_validate_df = get_transactions_agg_by_period(transact_agg_by_comp_fortnight_validate_df, 'Fortnight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transact_agg_comp_week_filled_adjusted_df.to_csv('../data/curated/final_model/weekly_agg_merchant_transactions_NOFRAUD.csv', index=False)\n",
    "\n",
    "transact_agg_comp_fortnight_filled_adjusted_df.to_csv('../data/curated/final_model/fortnightly_agg_merchant_transactions_NOFRAUD.csv', index=False)\n",
    "\n",
    "transact_agg_comp_fortnight_fill_adjusted_train_df.to_csv('../data/curated/final_model/fortnightly_agg_merchant_transactions_train_NOFRAUD.csv', index=False)\n",
    "\n",
    "transact_agg_comp_fortnight_fill_adjusted_validate_df.to_csv('../data/curated/final_model/fortnightly_agg_merchant_transactions_validate_NOFRAUD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(transact_agg_comp_week_filled_adjusted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162709"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_fortnight_filled_adjusted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_fortnight_fill_adjusted_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62021"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_fortnight_fill_adjusted_validate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect how many merchants have less than i weeks on record\n",
    "\n",
    "# nweeks = transact_agg_comp_week_df.groupby(['merchant_abn']).agg({'Week': 'count'})\n",
    "\n",
    "# print(\"Number of merchants with less than i weeks of activity\")\n",
    "# for i in range(20):\n",
    "\n",
    "#     print(i, len(nweeks[nweeks['Week']<= i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nperiods_and_drop_low_counts(transact_agg_comp_periods_df, period, low_counts=2):\n",
    "    \"\"\" get nperiod values and also drop merchants that don't have enough periods of records \"\"\"\n",
    "\n",
    "    # get number of periods with observed data per merchant\n",
    "    n_periods = transact_agg_comp_periods_df.groupby(['merchant_abn']).agg({period: 'count'})\n",
    "    n_periods = n_periods.rename(columns = {period: 'n_periods'})\n",
    "\n",
    "    # get list of low count abns and drop\n",
    "    low_count_merchants = n_periods[n_periods['n_periods'] <= low_counts].index\n",
    "\n",
    "    for abn in list(low_count_merchants):\n",
    "        transact_agg_comp_periods_df = transact_agg_comp_periods_df[transact_agg_comp_periods_df['merchant_abn'] != abn]\n",
    "\n",
    "    return transact_agg_comp_periods_df, n_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sd_nperiods(transact_agg_comp_period_df, n_periods):\n",
    "     \"\"\" Helper to get mean, sd and nperiods of merchants \"\"\"\n",
    "\n",
    "     # create replicate column to allow for two aggregations on the same column of data\n",
    "     transact_agg_comp_period_df['sum_transactions2'] = transact_agg_comp_period_df['sum_transactions']\n",
    "     mean_sd = transact_agg_comp_period_df.groupby(['merchant_abn']).agg({'sum_transactions': mean, 'sum_transactions2': stdev})\n",
    "\n",
    "     mean_sd = mean_sd.rename(columns = {'sum_transactions': 'mean',\\\n",
    "          'sum_transactions2': 'stdev'})\n",
    "\n",
    "     mean_sd = mean_sd.reset_index()\n",
    "     \n",
    "     mean_sd_nperiods = mean_sd.merge(n_periods, on = ['merchant_abn'], how = 'inner')\n",
    "\n",
    "     return mean_sd_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merchant_mean_sd_nperiods(transact_agg_comp_periods_df, period, low_counts = 2):\n",
    "    \"\"\" Function that runs helpers to get the merchant data in mean, sd and nperiods \"\"\"\n",
    "\n",
    "    transact_agg_comp_periods_df, n_periods = get_nperiods_and_drop_low_counts(transact_agg_comp_periods_df, period, low_counts)\n",
    "\n",
    "    mean_sd_nperiods = get_mean_sd_nperiods(transact_agg_comp_periods_df, n_periods)\n",
    "\n",
    "    return mean_sd_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_sd_nperiods_week = get_merchant_mean_sd_nperiods(transact_agg_comp_week_filled_adjusted_df, 'Week', low_counts = 2)\n",
    "mean_sd_nperiods_fortnight = get_merchant_mean_sd_nperiods(transact_agg_comp_fortnight_filled_adjusted_df, 'Fortnight', low_counts = 2)\n",
    "\n",
    "mean_sd_nperiods_fortnight_train = get_merchant_mean_sd_nperiods(transact_agg_comp_fortnight_fill_adjusted_train_df, 'Fortnight', low_counts = 2)\n",
    "\n",
    "mean_sd_nperiods_fortnight_validate = get_merchant_mean_sd_nperiods(transact_agg_comp_fortnight_fill_adjusted_validate_df, 'Fortnight', low_counts = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "      <th>n_periods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023283211</td>\n",
       "      <td>15774.435579</td>\n",
       "      <td>3347.782165</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10142254217</td>\n",
       "      <td>2637.764272</td>\n",
       "      <td>755.355220</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10187291046</td>\n",
       "      <td>899.763911</td>\n",
       "      <td>445.159257</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10192359162</td>\n",
       "      <td>3851.794656</td>\n",
       "      <td>1658.963593</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10206519221</td>\n",
       "      <td>8077.396691</td>\n",
       "      <td>1953.558746</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>99938978285</td>\n",
       "      <td>11761.500762</td>\n",
       "      <td>2395.220455</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>99974311662</td>\n",
       "      <td>846.636608</td>\n",
       "      <td>640.102616</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>99976658299</td>\n",
       "      <td>78289.017333</td>\n",
       "      <td>16801.147773</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>99987905597</td>\n",
       "      <td>1464.569596</td>\n",
       "      <td>903.799829</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>99990536339</td>\n",
       "      <td>1188.760678</td>\n",
       "      <td>1986.917612</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4377 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      merchant_abn          mean         stdev  n_periods\n",
       "0      10023283211  15774.435579   3347.782165         38\n",
       "1      10142254217   2637.764272    755.355220         38\n",
       "2      10187291046    899.763911    445.159257         38\n",
       "3      10192359162   3851.794656   1658.963593         38\n",
       "4      10206519221   8077.396691   1953.558746         38\n",
       "...            ...           ...           ...        ...\n",
       "4372   99938978285  11761.500762   2395.220455         38\n",
       "4373   99974311662    846.636608    640.102616         38\n",
       "4374   99976658299  78289.017333  16801.147773         38\n",
       "4375   99987905597   1464.569596    903.799829         38\n",
       "4376   99990536339   1188.760678   1986.917612         34\n",
       "\n",
       "[4377 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sd_nperiods_fortnight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market(transact_agg_comp_period_df, period):\n",
    "    \"\"\" get the sum of all merchants data by period \"\"\"\n",
    "\n",
    "    market = transact_agg_comp_period_df.groupby(['Year', period])\\\n",
    "        .agg({'sum_transactions': sum, 'number_of_customers': 'count', 'distinct_customers': lambda x: x.nunique()})\n",
    "    \n",
    "    market = market.reset_index()\n",
    "\n",
    "    return market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_mean_and_sd(market):\n",
    "    \"\"\" get the mean and sd of the market \"\"\"\n",
    "\n",
    "    market_mean = mean(market['sum_transactions'])\n",
    "    market_sd = stdev(market['sum_transactions'])\n",
    "\n",
    "    return market_mean, market_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_and_stats(transact_agg_comp_period_df, period):\n",
    "\n",
    "    market = get_market(transact_agg_comp_period_df, period)\n",
    "\n",
    "    market_mean, market_sd = get_market_mean_and_sd(market)\n",
    "\n",
    "    return market, market_mean, market_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market_week, market_mean_week, market_sd_week = get_market_and_stats(transact_agg_comp_week_df, 'Week')\n",
    "\n",
    "market_fortnight, market_mean_fortnight, market_sd_fortnight = get_market_and_stats(transact_agg_comp_fortnight_df, 'Fortnight')\n",
    "\n",
    "market_fortnight_train, market_mean_fortnight_train, market_sd_fortnight_train = get_market_and_stats(transact_agg_comp_fortnight_df, 'Fortnight')\n",
    "\n",
    "market_fortnight_validate, market_mean_fortnight_validate, market_sd_fortnight_validate = get_market_and_stats(transact_agg_comp_fortnight_df, 'Fortnight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market_week.to_csv('../data/curated/final_model/market-all_by_week_NOFRAUD.csv', index=False)\n",
    "\n",
    "market_fortnight.to_csv('../data/curated/final_model/market-all_by_fortnight_NOFRAUD.csv', index=False)\n",
    "\n",
    "market_fortnight_train.to_csv('../data/curated/final_model/market-all_by_fortnight_train_NOFRAUD.csv', index=False)\n",
    "\n",
    "market_fortnight_validate.to_csv('../data/curated/final_model/market-all_by_fortnight_validate_NOFRAUD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {'Fortnight': {'mean': market_mean_fortnight, 'sd': market_sd_fortnight}}\n",
    "\n",
    "Data = json.dumps(str(json_data))\n",
    "\n",
    "with open('../data/curated/final_model/Market_stats.json', 'w') as f:\n",
    "    json.dump(Data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_df(transact_agg_comp_period_df, market, period):\n",
    "    \"\"\" get dataframe of correlations \"\"\"\n",
    "\n",
    "    merchant_abns = list()\n",
    "    corr = list()\n",
    "\n",
    "    # get each abn's periodic data, left join on market, and then get correlation\n",
    "    for abn in list(set(transact_agg_comp_period_df['merchant_abn'])):\n",
    "        merchant = transact_agg_comp_period_df[transact_agg_comp_period_df['merchant_abn'] == abn]\n",
    "\n",
    "        merchant_market = merchant.merge(market, how = 'left', on = ['Year', period])\n",
    "        merchant_abns.append(abn)\n",
    "        corr.append(np.corrcoef(merchant_market['sum_transactions_x'], merchant_market['sum_transactions_y'])[0][1])\n",
    "\n",
    "    corr_df = pd.DataFrame({'merchant_abn': merchant_abns, 'corr': corr})\n",
    "\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sd_corr_nperiods(mean_sd_nperiods, corr_df, market_sd):\n",
    "    \"\"\" add corr and corr related variables to mean, sd dataframe \"\"\"\n",
    "\n",
    "    mean_sd_corr_nperiods = mean_sd_nperiods.merge(corr_df, on = ['merchant_abn'], how = 'inner')\n",
    "    mean_sd_corr_nperiods['covar'] = mean_sd_corr_nperiods['stdev'] * mean_sd_corr_nperiods['corr'] * market_sd\n",
    "    mean_sd_corr_nperiods['beta'] = mean_sd_corr_nperiods['covar']/(np.power(market_sd,2))\n",
    "    \n",
    "    return mean_sd_corr_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(transact_agg_comp_period_df, market, period, mean_sd_nperiods, market_sd):\n",
    "    \n",
    "    corr_df = get_corr_df(transact_agg_comp_period_df, market, period)\n",
    "\n",
    "    mean_sd_corr_nperiods = get_mean_sd_corr_nperiods(mean_sd_nperiods, corr_df, market_sd)\n",
    "\n",
    "    return mean_sd_corr_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    }
   ],
   "source": [
    "# mean_sd_corr_nperiods_week = get_corr(transact_agg_comp_week_df, market_week, \\\n",
    "    # 'Week', mean_sd_nperiods_week, market_sd_week)\n",
    "mean_sd_corr_nperiods_fortnight = get_corr(transact_agg_comp_fortnight_df, market_fortnight, \\\n",
    "    'Fortnight', mean_sd_nperiods_fortnight, market_sd_fortnight)\n",
    "\n",
    "mean_sd_corr_nperiods_fortnight_train = get_corr(transact_agg_by_comp_fortnight_train_df, market_fortnight_train, \\\n",
    "    'Fortnight', mean_sd_nperiods_fortnight_train, market_sd_fortnight_train)\n",
    "\n",
    "mean_sd_corr_nperiods_fortnight_validate = get_corr(transact_agg_by_comp_fortnight_validate_df, market_fortnight_validate, \\\n",
    "    'Fortnight', mean_sd_nperiods_fortnight_validate, market_sd_fortnight_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_sd_corr_nperiods_week.to_csv('../data/curated/final_model/agg_weekly_mean_sd_marketcorr_NOFRAUD.csv', index=False)\n",
    "mean_sd_corr_nperiods_fortnight.to_csv('../data/curated/final_model/agg_fortnightly_mean_sd_marketcorr_NOFRAUD.csv', index=False)\n",
    "\n",
    "mean_sd_corr_nperiods_fortnight_train.to_csv('../data/curated/final_model/agg_fortnightly_mean_sd_marketcorr_train_NOFRAUD.csv', index=False)\n",
    "\n",
    "mean_sd_corr_nperiods_fortnight_validate.to_csv('../data/curated/final_model/agg_fortnightly_mean_sd_marketcorr_validate_NOFRAUD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_sd_corr_nperiods_week.describe().drop(['merchant_abn', 'n_periods'], axis=1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "      <th>corr</th>\n",
       "      <th>covar</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11526.432943</td>\n",
       "      <td>3404.584648</td>\n",
       "      <td>0.486950</td>\n",
       "      <td>2.905469e+10</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26614.215973</td>\n",
       "      <td>5654.838346</td>\n",
       "      <td>0.368809</td>\n",
       "      <td>6.587277e+10</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.485670</td>\n",
       "      <td>41.942681</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-4.444844e+10</td>\n",
       "      <td>-0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>800.638268</td>\n",
       "      <td>676.461301</td>\n",
       "      <td>0.238953</td>\n",
       "      <td>1.734745e+09</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2875.474140</td>\n",
       "      <td>1564.745386</td>\n",
       "      <td>0.521843</td>\n",
       "      <td>7.857930e+09</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13136.571367</td>\n",
       "      <td>4196.927015</td>\n",
       "      <td>0.804873</td>\n",
       "      <td>3.449858e+10</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>221706.800818</td>\n",
       "      <td>50268.592322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.815408e+11</td>\n",
       "      <td>0.003955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean         stdev      corr         covar      beta\n",
       "mean   11526.432943   3404.584648  0.486950  2.905469e+10  0.000198\n",
       "std    26614.215973   5654.838346  0.368809  6.587277e+10  0.000448\n",
       "min       10.485670     41.942681 -1.000000 -4.444844e+10 -0.000302\n",
       "25%      800.638268    676.461301  0.238953  1.734745e+09  0.000012\n",
       "50%     2875.474140   1564.745386  0.521843  7.857930e+09  0.000053\n",
       "75%    13136.571367   4196.927015  0.804873  3.449858e+10  0.000235\n",
       "max   221706.800818  50268.592322  1.000000  5.815408e+11  0.003955"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sd_corr_nperiods_fortnight.describe().drop(['merchant_abn', 'n_periods'], axis=1)[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
